{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MAN1108/github-test/blob/main/FINETUNING_GPT_WITH_METRICS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x8Bv3RSQgT5",
        "outputId": "809e84df-26a8-4957-9b0a-2f6b3adcb167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.27.0-py3-none-any.whl (314 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/314.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/314.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.27.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "V0vjnM26SLIL",
        "outputId": "51ddc68d-e91d-49c7-a100-71289192b2b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  What is the name of the place where students b...   \n",
              "1  What did Wendelin do to make sure she wasn't r...   \n",
              "2  What is the name of the spell used to disarm a...   \n",
              "3  What impact does Harry’s friendship with Hermi...   \n",
              "4  What is the name of the magical object that is...   \n",
              "\n",
              "                                              answer  \\\n",
              "0                                       Diagon Alley   \n",
              "1                                    Wore disguises.   \n",
              "2                                       Expelliarmus   \n",
              "3  It helps him see the world from different pers...   \n",
              "4                                     Hermione's Bag   \n",
              "\n",
              "                                                text  \n",
              "0  <s>[INST] <<SYS>> Answer as briefly as you can...  \n",
              "1  <s>[INST] <<SYS>> Answer as briefly as you can...  \n",
              "2  <s>[INST] <<SYS>> Answer as briefly as you can...  \n",
              "3  <s>[INST] <<SYS>> Answer as briefly as you can...  \n",
              "4  <s>[INST] <<SYS>> Answer as briefly as you can...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46dcb64e-73f8-41a8-89f3-2ec567490190\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the name of the place where students b...</td>\n",
              "      <td>Diagon Alley</td>\n",
              "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; Answer as briefly as you can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What did Wendelin do to make sure she wasn't r...</td>\n",
              "      <td>Wore disguises.</td>\n",
              "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; Answer as briefly as you can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the name of the spell used to disarm a...</td>\n",
              "      <td>Expelliarmus</td>\n",
              "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; Answer as briefly as you can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What impact does Harry’s friendship with Hermi...</td>\n",
              "      <td>It helps him see the world from different pers...</td>\n",
              "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; Answer as briefly as you can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the name of the magical object that is...</td>\n",
              "      <td>Hermione's Bag</td>\n",
              "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; Answer as briefly as you can...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46dcb64e-73f8-41a8-89f3-2ec567490190')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46dcb64e-73f8-41a8-89f3-2ec567490190 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46dcb64e-73f8-41a8-89f3-2ec567490190');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4412f391-22ea-45ba-b89f-54c7ea542c91\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4412f391-22ea-45ba-b89f-54c7ea542c91')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4412f391-22ea-45ba-b89f-54c7ea542c91 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2219,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1453,\n        \"samples\": [\n          \"What is another name for the Alihotsy tree?\",\n          \"Which of Voldemort\\u2019s Horcruxes do Harry and Dumbledore track down\\u2014but it turns out to be a fake?\",\n          \"What is the title of the seventh book in the series?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1178,\n        \"samples\": [\n          \"Charm\",\n          \"A piece of the person you want to turn into\",\n          \"Caretaker\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1480,\n        \"samples\": [\n          \"<s>[INST] <<SYS>> Answer as briefly as you can to the following question. You are required to give a one-shot answer: <</SYS>> What is the incantation for a Confundus charm? [/INST] Confundo </s>\",\n          \"<s>[INST] <<SYS>> Answer as briefly as you can to the following question. You are required to give a one-shot answer: <</SYS>> What was Gilderoy Lockhart's best Spell? [/INST] Obliviate </s>\",\n          \"<s>[INST] <<SYS>> Answer as briefly as you can to the following question. You are required to give a one-shot answer: <</SYS>> Wiggentrees are guarded by what creature? [/INST] Bowtruckle </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/sample_data/train.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tlbrcUMUEiw",
        "outputId": "8bba5e1f-6e7c-4187-90f6-74ffc234dfcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': 'What is the name of the place where students buy their school supplies?'},\n",
              " {'role': 'assistant', 'content': '\"Diagon Alley\"'}]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "def convert_to_gpt35_format(dataset):\n",
        "    fine_tuning_data = []\n",
        "    for _, row in dataset.iterrows():\n",
        "        json_response = f'\"{ row[\"answer\"]}\"'\n",
        "\n",
        "        fine_tuning_data.append({\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": row['question']},\n",
        "                {\"role\": \"assistant\", \"content\": json_response}\n",
        "            ]\n",
        "        })\n",
        "    return fine_tuning_data\n",
        "\n",
        "dataset = pd.read_csv('/content/sample_data/train_1.csv')\n",
        "converted_data = convert_to_gpt35_format(dataset)\n",
        "converted_data[0]['messages']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "C3_qXsSdU_5P",
        "outputId": "e80cc919-eb39-45a1-c965-3b3d8d647cb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Diagon Alley'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "json.loads(converted_data[0]['messages'][-1]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WoKcFYBVKBM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified splitting. Assuming 'Top Category' can be used for stratification\n",
        "train_data, val_data = train_test_split(\n",
        "    converted_data,\n",
        "    test_size=0.2,\n",
        "      random_state=42  # for reproducibility\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZzARKVFVPsZ",
        "outputId": "bfacdcd7-f442-4a77-d16b-13686b133543"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "type(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ieIjKvYVUwb"
      },
      "outputs": [],
      "source": [
        "def write_to_jsonl(data, file_path):\n",
        "    with open(file_path, \"w\") as file:\n",
        "        for entry in data:\n",
        "            json.dump(entry, file)\n",
        "            file.write('\\n')\n",
        "\n",
        "\n",
        "training_file_name = \"train_1.jsonl\"\n",
        "validation_file_name = \"val_1.jsonl\"\n",
        "\n",
        "write_to_jsonl(train_data, training_file_name)\n",
        "write_to_jsonl(val_data, validation_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-HfwzuQcVcj7"
      },
      "outputs": [],
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"sk-proj-6wOQAJcLyedBOXztO2NlT3BlbkFJ1EFTuEvl67jyNuo67Nw7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffgm5mx3Vlgq",
        "outputId": "7bb534ee-aadf-49e0-896e-7bc7d4611672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training file id: file-OMXb3F9OmEoGnlqIrjHCCoXM\n",
            "Validation file id: file-Cx8VBjy348iACYf0k0oOIFL1\n"
          ]
        }
      ],
      "source": [
        "training_file = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(\"Training file id:\", training_file.id)\n",
        "print(\"Validation file id:\", validation_file.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hd_2miQVraj",
        "outputId": "919a1eb3-d271-4cba-eb31-bdbd532d0512"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-8RmoQl8wQzZNzE3GkftlXrpy', created_at=1714630372, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=1681322092, status='validating_files', trained_tokens=None, training_file='file-OMXb3F9OmEoGnlqIrjHCCoXM', validation_file='file-Cx8VBjy348iACYf0k0oOIFL1', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1')"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "\n",
        "suffix_name = \"Harry_porter_1\"\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    validation_file=validation_file.id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDIF7qBJV7Ad",
        "outputId": "5331dc3b-34cc-4684-a2cb-42977c17acdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-8RmoQl8wQzZNzE3GkftlXrpy', created_at=1714630372, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:harry-porter-1:9KK6rOs1', finished_at=1714630888, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=['file-nBEeytjUGcfHDr5oiIZQD3Ng'], seed=1681322092, status='succeeded', trained_tokens=7719, training_file='file-OMXb3F9OmEoGnlqIrjHCCoXM', validation_file='file-Cx8VBjy348iACYf0k0oOIFL1', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-BQcbxBWCa35CxvcpbtMAf8et', created_at=1714629509, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=476598727, status='cancelled', trained_tokens=None, training_file='file-nDGe9L04I8lRcWgPw9xQ2cEi', validation_file='file-yio2NvD69KPVsf8D0TaDc6zq', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-VFB033lZcpSYPWsKasUV58hR', created_at=1714629367, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=312661385, status='failed', trained_tokens=None, training_file='file-jAWgbRd4zzmP8HWfSbmWdCLk', validation_file='file-0rDeBEzg3Bxij3ulHtPXE7SJ', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-nFsH2GZUExeCM5GHJDo1ppg7', created_at=1714628344, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=307589493, status='failed', trained_tokens=None, training_file='file-WtUzBrXJiRnMYUh7ca6AbuTp', validation_file='file-zvh4EcqfWcRkcld4uXkYOtdD', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-9TByoJueyPzmB3BnjGAW7LTF', created_at=1714628187, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=1459871782, status='failed', trained_tokens=None, training_file='file-wDgb1zjl5HgibHxtDG164iUs', validation_file='file-XrUITQQpCCnDWihNAE6zJbCS', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-5A1ioxxoy59yARpNQUndBi3S', created_at=1714628053, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=342170852, status='failed', trained_tokens=None, training_file='file-Mda1DqUnEBcCSAal5jcrekd3', validation_file='file-clRzxaMcaxvKKD7ZyTuhrWGm', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-9lBYCWSAkKfln4YqFfOOOjOS', created_at=1714627864, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=1527662511, status='failed', trained_tokens=None, training_file='file-Mda1DqUnEBcCSAal5jcrekd3', validation_file='file-clRzxaMcaxvKKD7ZyTuhrWGm', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-orQp1wrrAoYWrG51GiMUrDmo', created_at=1714627592, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=838891074, status='failed', trained_tokens=None, training_file='file-pSyy50nGaUZjDtgKKUdNyPzP', validation_file='file-zyr2GZ0JbHkOYtPXey7g6b4L', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-4XZTWbVoF8w6osKkLKUmPFDw', created_at=1714625955, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=197163827, status='failed', trained_tokens=None, training_file='file-NVhBBxxhRBYRhK6fYWCyM4E5', validation_file='file-0owa2Vekq5kLvEvIMzxl6HjK', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1'), FineTuningJob(id='ftjob-2ZqwxDNYLiwKgHh3ruuY3Qt4', created_at=1714625679, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Expected file to have JSONL format, where every line is a valid JSON dictionary. Line 4 is not a dictionary.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=[], seed=1787638568, status='failed', trained_tokens=None, training_file='file-oX4xhmTmDzxK5dkdcXZrFAKo', validation_file='file-8XpgW2aopcAiNl4Vv2xU5O5o', estimated_finish=None, integrations=[], user_provided_suffix='Harry_porter_1')], object='list', has_more=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\n",
        "client.fine_tuning.jobs.list(limit=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzuCH84WEMu",
        "outputId": "d1a2f788-9479-4906-df19-d931f6b13acb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-Toh1WzLMPrlvxT2fZl3krdoI', created_at=1714590937, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:question-answering:9KAUxe6O', finished_at=1714593941, hyperparameters=Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-HZKLAzY4JCgQsHV6XT6RYrNx', result_files=['file-qvp96ojUeNImpgFJjlDyLMjw'], seed=91797584, status='succeeded', trained_tokens=157047, training_file='file-VJhx0fw4ZBo6RoAoITxSkCj8', validation_file='file-iwMEh0N1IQyi8CLXoWcSp5ji', estimated_finish=None, integrations=[], user_provided_suffix='Question_Answering')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "response = client.fine_tuning.jobs.retrieve(\"ftjob-Toh1WzLMPrlvxT2fZl3krdoI\")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHhoOsOwYsI1",
        "outputId": "ace78b5e-f6bc-4143-fa22-e9065befec7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine-tuned model id: ft:gpt-3.5-turbo-0125:personal:question-answering:9KAUxe6O\n"
          ]
        }
      ],
      "source": [
        "fine_tuned_model_id = response.fine_tuned_model\n",
        "print(\"\\nFine-tuned model id:\", fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jdmb2hNukAQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lr5BsY6rZtcN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def format_test(row):\n",
        "\n",
        "    formatted_message = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": row['question']\n",
        "        }\n",
        "    ]\n",
        "    return formatted_message\n",
        "\n",
        "\n",
        "def predict(test_messages, fine_tuned_model_id):\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=50\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bUKQGEFiZ6Gj"
      },
      "outputs": [],
      "source": [
        "def store_predictions(test_df, fine_tuned_model_id):\n",
        "\n",
        "    print(\"fine_tuned_model_id\",fine_tuned_model_id)\n",
        "    test_df['Prediction'] = None\n",
        "\n",
        "    for index, row in test_df.iterrows():\n",
        "        test_message = format_test(row)\n",
        "        prediction_result = predict(test_message, fine_tuned_model_id)\n",
        "        test_df.at[index, 'Prediction'] = prediction_result\n",
        "\n",
        "\n",
        "    test_df.to_csv(\"predictions_dataset_by_Fine-tuning-gpt-3.5.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQPnL5wraBeL",
        "outputId": "080a0b55-88af-4c35-c66e-2dcad7ba626d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fine_tuned_model_id ft:gpt-3.5-turbo-0125:personal:question-answering:9KAUxe6O\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv(\"/content/sample_data/dataset_for_finetuning_GPT3.5.csv\")\n",
        "store_predictions(test_df, fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "ground_truth = test_df['answer'].tolist()\n",
        "predictions = test_df['Prediction'].tolist()\n",
        "\n",
        "\n",
        "def calculate_metrics(ground_truth, predictions):\n",
        "  \"\"\"\n",
        "  Calculates and prints various evaluation metrics for question answering.\n",
        "\n",
        "  Args:\n",
        "      ground_truth: A list of strings containing the correct answers.\n",
        "      predictions:  A list of strings containing the model's predicted answers.\n",
        "\n",
        "  Returns:\n",
        "      A dictionary containing the calculated metrics (accuracy, precision, recall, F1-score).\n",
        "  \"\"\"\n",
        "  metrics = {}\n",
        "\n",
        "  # Ensure equal list lengths (handle cases with missing predictions)\n",
        "  ground_truth = ground_truth[:len(predictions)]\n",
        "  predictions = predictions[:len(ground_truth)]\n",
        "  predictions = [pred if pred is not None else \"I'm not sure\" for pred in predictions]\n",
        "  # Calculate metrics\n",
        "  metrics[\"accuracy\"] = accuracy_score(ground_truth, predictions)\n",
        "  metrics[\"precision\"] = precision_score(ground_truth, predictions, average='weighted')  # Weighted precision for imbalanced datasets\n",
        "  metrics[\"recall\"] = recall_score(ground_truth, predictions, average='weighted')  # Weighted recall for imbalanced datasets\n",
        "  metrics[\"f1\"] = f1_score(ground_truth, predictions, average='weighted')  # Weighted F1-score for imbalanced datasets\n",
        "\n",
        "  # Print Metric Results\n",
        "  print(\"Evaluation Metrics:\")\n",
        "  for metric_name, value in metrics.items():\n",
        "    print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "  return metrics\n",
        "\n",
        "# ... (Your code for generating ground_truth and predictions) ...\n",
        "\n",
        "metrics = calculate_metrics(ground_truth, predictions)"
      ],
      "metadata": {
        "id": "wj9etBRzA1K6",
        "outputId": "57def548-2219-442e-a777-f666acc76d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "accuracy: 0.5000\n",
            "precision: 0.5000\n",
            "recall: 0.5000\n",
            "f1: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPgJWC31+z6EVhVy0INkyCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}